# ğŸ¥ Anatomy-Aware CT Scan Denoising

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Advanced Deep Learning Approaches for Radiation Dose Reduction in Medical Imaging**

This repository contains a comprehensive collection of state-of-the-art deep learning models for CT scan denoising with anatomy-aware processing. Our approach enables significant radiation dose reduction while maintaining diagnostic image quality.

---

## ğŸ¯ Project Overview

Low-dose CT imaging is crucial for reducing radiation exposure in patients, but it introduces noise and artifacts that degrade image quality. This project implements and compares multiple deep learning architectures to perform anatomy-aware denoising on low-dose CT scans across different radiation dose levels.

### Key Features

âœ… **Multi-Model Architecture**: Compare 6 different deep learning models  
âœ… **Multi-Dose Evaluation**: Evaluate performance across 4 radiation dose levels (10%, 25%, 50%, 70%)  
âœ… **Anatomy-Aware Processing**: Models trained with knowledge of anatomical structures  
âœ… **Comprehensive Metrics**: PSNR, SSIM, RMSE evaluation  
âœ… **Teacher-Student Training**: Knowledge distillation approach for improved performance  

---

## ğŸ“Š Repository Structure

```
Anatomy-aware-CT-scan-denoising/
â”œâ”€â”€ Baseline/                 # Basic Autoencoder Implementation
â”‚   â”œâ”€â”€ training_baseline.py  # Training script
â”‚   â”œâ”€â”€ evaluate_baseline.py  # Evaluation script
â”‚   â””â”€â”€ eval_images/          # Sample outputs
â”‚
â”œâ”€â”€ Nafnet/                   # NAFNet (Normalized Attention FNet)
â”‚   â”œâ”€â”€ train_nafnet_mlp.py   # MLP variant training
â”‚   â”œâ”€â”€ evaluate_nafnet.py    # Evaluation
â”‚   â””â”€â”€ eval_images_nafnet_mlp/
â”‚
â”œâ”€â”€ RadIMG+Nafnet/            # RAD-IMG enhanced NAFNet
â”‚   â”œâ”€â”€ train_nafnet_radimg.py
â”‚   â”œâ”€â”€ evaluate_rad.py
â”‚   â””â”€â”€ eval_images_rad_mlp/
â”‚
â”œâ”€â”€ Resnet/                   # ResNet-based Architecture
â”‚   â”œâ”€â”€ train_resnet.py
â”‚   â”œâ”€â”€ evaluate_resnet.py
â”‚   â””â”€â”€ eval_images_resnet/
â”‚
â”œâ”€â”€ unet/                     # U-Net Architecture
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ evaluate_unet.py
â”‚   â””â”€â”€ eval_images_unet/
â”‚
â”œâ”€â”€ Wo_dose/                  # Ablation Study (Without Dose)
â”‚   â”œâ”€â”€ train_wodose.py
â”‚   â”œâ”€â”€ evaluate_no_dose.py
â”‚   â””â”€â”€ eval_images_ablation/
â”‚
â”œâ”€â”€ Noise Simulation/         # Data Preparation
â”‚   â”œâ”€â”€ data_LoD0.py          # Low-dose simulation
â”‚   â””â”€â”€ data_mayo.py          # Mayo clinic data processing
â”‚
â”œâ”€â”€ Results/                  # Model Comparison Results
â”‚   â”œâ”€â”€ model_comparisons.md
â”‚   â”œâ”€â”€ metrics_summary.csv
â”‚   â””â”€â”€ visualizations/
â”‚
â”œâ”€â”€ Presentation - Anatomy-Aware Denoising.pdf
â””â”€â”€ README.md
```

---

## ğŸ§  Implemented Models

| Model | Architecture | Parameters | Focus Area |
|-------|-------------|-----------|------------|
| **Baseline** | Autoencoder | Conv + Deconv | Foundation model |
| **NAFNet** | Normalized Attention FNet | Attention-based | Feature refinement |
| **RAD-IMG + NAFNet** | NAFNet + RadIMG | Enhanced attention | Anatomy-aware processing |
| **ResNet** | Residual Networks | Skip connections | Deep feature learning |
| **U-Net** | Encoder-Decoder | Dense connections | Semantic segmentation-style |
| **Wo_Dose** | No dose conditioning | Ablation baseline | Performance impact analysis |

---

## ğŸ“ˆ Performance Metrics

Our models are evaluated on the following metrics:

- **PSNR (Peak Signal-to-Noise Ratio)**: Higher is better (typical range: 20-40 dB)
- **SSIM (Structural Similarity Index)**: Range [0,1], higher indicates better structural preservation
- **RMSE (Root Mean Square Error)**: Lower is better
- **MSE (Mean Square Error)**: Pixel-level error measurement

### Evaluation by Radiation Dose

Models are tested across 4 dose levels:
- **10% Dose**: Extreme noise reduction scenario
- **25% Dose**: Challenging noise environment
- **50% Dose**: Moderate dose level
- **70% Dose**: Near-standard dose

---

## ğŸš€ Training Pipeline

### Model Training

The teacher network is trained on normal-dose CT (NDCT) images:

```python
python Baseline/training_baseline.py \
    --mayo_root /path/to/data \
    --epochs_teacher 100 \
    --batch 8 \
    --lr 2e-4
    --epochs_student 150 \
    --lam_lat 1.0 \
    --lam_rec 1.0
```



## ğŸ“¥ Installation

### Requirements

- Python 3.8 or higher
- PyTorch 1.9+
- NumPy, Pillow, tqdm
- TensorBoard for visualization

### Setup

```bash
# Clone the repository
git clone https://github.com/Ajay02423/Anatomy-aware-CT-scan-denoising.git
cd Anatomy-aware-CT-scan-denoising

# Install dependencies
pip install torch torchvision
pip install numpy pillow tqdm tensorboard
```

---

## ğŸ“ Training Configuration

Key hyperparameters used across models:

| Parameter | Value | Description |
|-----------|-------|-------------|
| Batch Size | 8 | Samples per iteration |
| Learning Rate | 2e-4 | Adam optimizer |
| Teacher Epochs | 100 | NDCT autoencoder training |
| Student Epochs | 150 | LDCT encoder training |
| Î±_SSIM | 0.2 | SSIM loss weight |
| Î»_lat | 1.0 | Latent space loss weight |
| Î»_rec | 1.0 | Reconstruction loss weight |

---

## ğŸ“Š Normalization Strategy

Images are normalized using fixed windowing:

```python
MIN_HU = -1000.0  # Minimum Hounsfield Unit
MAX_HU = 1000.0   # Maximum Hounsfield Unit
# Normalize to [0, 1] then to [-1, 1] for Tanh activation
```

---

## ğŸ” Loss Functions

### Teacher Training
```
Loss = L1_Loss + Î±_SSIM Ã— (1 - SSIM)
```

### Student Training
```
Loss = Î»_lat Ã— MSE_Latent + Î»_rec Ã— L1_Reconstruction
```

---

## ğŸ“ Dataset Information

The project uses:
- **LDCT Pairs Dataset**: Low-dose and Normal-dose CT scan pairs
- **Doses**: 10%, 25%, 50%, 70% of standard radiation
- **Format**: .npy files with Hounsfield Unit values
- **Normalization**: Per-sample HU windowing

---

## ğŸ¨ Results & Visualization

Sample outputs are saved in each model folder:
- `training_samples/`: Progressive training visualization
- `eval_images/`: Model evaluation results
- `dose_wise_results/`: Performance per radiation dose

---

## ğŸ“š Model Training Details

### Baseline Encoder Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input (1, H, W)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv Block (1 â†’ 64)                 â”‚
â”‚ MaxPool â†’ Conv Block (64 â†’ 128)     â”‚
â”‚ MaxPool â†’ Conv Block (128 â†’ 256)    â”‚
â”‚ MaxPool â†’ Conv Block (256 â†’ 512)    â”‚
â”‚ MaxPool â†’ Conv Block (512 â†’ 512)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ Latent Space
```

### Baseline Decoder Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Latent (512, h, w)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DeconvBlock (512 â†’ 512)             â”‚
â”‚ ConvBlock â†’ DeconvBlock (512 â†’ 256) â”‚
â”‚ ConvBlock â†’ DeconvBlock (256 â†’ 128) â”‚
â”‚ ConvBlock â†’ DeconvBlock (128 â†’ 64)  â”‚
â”‚ Conv (64 â†’ 1) + Tanh                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Key Findings

1. **Dose Dependency**: Model performance scales with radiation dose
2. **Anatomy Awareness**: RAD-IMG enhancement shows consistent improvements
3. **Trade-offs**: Balance between noise reduction and detail preservation
4. **Generalization**: Models trained on one dose generalize reasonably to others

---

## ğŸ“– How to Evaluate

```bash
# Evaluate Baseline model
python Baseline/evaluate_baseline.py \
    --model_path runs/final/student \
    --test_data /path/to/test

# Evaluate NAFNet
python Nafnet/evaluate_nafnet.py \
    --model_path runs/final/student \
    --test_data /path/to/test
```

---

## ğŸ”„ Knowledge Distillation Approach

Our training uses a novel teacher-student framework:

1. **Teacher Network**: Learns to denoise normal-dose images
2. **Student Network**: Learns from teacher's latent representations
3. **Knowledge Transfer**: Minimize latent space divergence
4. **Dose Agnostic**: Student works across all dose levels

---

</div>




## ğŸ—ï¸ Architecture

### Training Pipeline

Our model uses a teacher-student knowledge distillation approach with the following flow:

- **LDCT Input**: Low-dose CT with noise at various dose levels (10-70%)
- **Student Encoder**: Trainable encoder that learns to process noisy LDCT data
- **Dose Conditioning**: MLP (1-64) that adapts the student encoder based on dose level
- **Feature Map Distillation**: Layer-wise alignment of student features to teacher features
- **Teacher Encoder**: Frozen encoder trained only on clean NDCT images
- **Shared Decoder**: Reconstructs high-quality NDCT-like output

### Inference Pipeline

At inference time, only the student encoder and decoder are used:

1. Input LDCT image and dose level (10-70%)
2. Pass through Student Encoder with dose-conditioning MLP
3. Generate latent representation compatible with teacher space
4. Decode to produce denoised NDCT-quality output

### NAFNet Encoder Architecture

The encoder uses a hierarchical downsampling approach:

```
Input: (B, 512, 512)
   â†“
Conv Head (3Ã—3)
   â†“
Down1: Stride 2, Channelsâ†’2, Conv 3Ã—3
   â†“
Down2: Stride 2, Channelsâ†’4, Conv 3Ã—3
   â†“
Down3: Stride 2, Channelsâ†’8, Conv 3Ã—3
   â†“
NAFBlock Ã—8 (Progressive stride-2 downsampling with:
  - Depthwise Conv (DWConv)
  - SimpleGate (Efficient gating)
  - SCA (Spatial-Channel Attention)
  - Residual scaling)
   â†“
Latent Projection: Conv 1Ã—1
   â†“
Output Latent Z: (B, 512, 64, 64)
```

### NAFNet Block Components

Each NAFBlock combines multiple efficient components:

1. **Layer Normalization**: Stabilizes features
2. **Conv 1Ã—1**: Channel mixing
3. **DWConv 3Ã—3**: Depthwise convolution for local feature extraction
4. **SimpleGate**: Lightweight element-wise gating mechanism
5. **SCA**: Spatial-Channel Attention with residual scaling
6. **Residual Connection**: Skip connection for stable gradient flow

**Why These Components?**
- **DWConv + SimpleGate**: Efficient noise suppression while preserving anatomical edges
- **SCA Attention**: Focused channel learning for selective feature importance
- **Residual Scaling**: Stable training convergence and gradient flow
- **Overall**: Balances efficiency with fidelity for real-time clinical deployment

---

## ğŸ“Š Results and Analysis

### Quantitative Performance

#### Performance Across Dose Levels

| Metric | **10% Dose** ||||**25% Dose** ||||**50% Dose** ||||**70% Dose** |
|--------|---|---|---|---|---|---|---|---|---|---|---|---|
|| GT | Baseline | Current | GT | Baseline | Current | GT | Baseline | Current | GT | Baseline | Current |
| **PSNR** | 20.34 | 37.69 | **40.81** | 34.92 | 37.42 | **39.99** | 38.28 | 38.14 | **43.42** | 33.83 | 38.19 | **44.01** |
| **SSIM** | 0.598 | 0.903 | **0.949** | 0.808 | 0.899 | **0.941** | 0.814 | 0.914 | **0.969** | 0.841 | 0.915 | **0.973** |
| **RMSE** | 0.0360 | 0.0132 | **0.00927** | 0.0184 | 0.0136 | **0.0102** | 0.0236 | 0.0125 | **0.00688** | 0.0224 | 0.0124 | **0.00643** |

**Key Findings:**
- Consistent +3-4 dB PSNR improvement over baseline
- Largest gains at extreme 10% dose (34 dB baseline improvement)
- SSIM â‰¥ 0.94 across all doses shows superior anatomical preservation
- No overfitting at high doses - performance remains excellent

#### Training Convergence

**Teacher Network:**
- Rapid initial drop in reconstruction loss
- Smooth convergence to stable NDCT latent representation
- Flattened tail indicates well-formed clean feature space

**Student Network:**
- Sharp initial decrease with successful knowledge distillation
- Settles into steady training band with minimal variance
- NAFNet variant achieves lower steady-state variance than ResNet/UNet baselines
- Indicates more stable and efficient learning of distilled knowledge

### Ablation Study: Architecture Comparison

**NAFNet** (RECOMMENDED)
- âœ… Efficient DWConv + SimpleGate for selective noise suppression
- âœ… Preserves high-frequency anatomical edges and fine details
- âœ… Lowest training variance â†’ fastest, most stable convergence
- âœ… Best quantitative metrics across all dose levels

**ResNet Baseline**
- âœ“ Stable residual connections
- âœ— Lacks gating mechanisms for selective feature processing
- âœ— Over-smooths small anatomical features
- âœ— Higher training variance than NAFNet

**UNet Baseline**
- âœ“ Skip connections help structure preservation
- âœ— Can reintroduce noise through skip pathways
- âœ— Lacks efficient gated micro-operations
- âœ— Slowest convergence, higher steady-state variance

**Verdict**: NAFNet's combination of depthwise convolutions and gating mechanisms provides the optimal balance of noise suppression and anatomical detail preservation.

### Dose-Conditioning Analysis

**Finding**: NAFNet with dose-conditioning performs similarly to NAFNet without explicit dose-conditioning.

**Implications:**
- Strong anatomical priors learned during training
- Robust dose-generalization inherent to NAFNet architecture
- Model demonstrates understanding of noise characteristics, not just memorization
- Dose-conditioning provides marginal additional benefit
- Simplified models still maintain strong cross-dose performance

### Qualitative Results by Dose Level

**10% Dose (Extreme Noise):**
- Input: Heavy noise, poor contrast
- Predicted (PSNR: 41.06, SSIM: 0.9609): Strong noise reduction with acceptable smoothing
- Assessment: Excellent denoising at most challenging dose

**25% Dose (Moderate-Low):**
- Input: Visible artifacts, degraded anatomy
- Predicted (PSNR: 42.82, SSIM: 0.9685): Well-preserved edges and small structures
- Assessment: Effective clinical-quality reconstruction

**50% Dose (Moderate):**
- Input: Subtle artifacts, reasonable detail
- Predicted (PSNR: 47.75, SSIM: 0.9908): Near-NDCT quality with preserved anatomy
- Assessment: Excellent structural and textural fidelity

**70% Dose (Low Noise):**
- Input: Minimal noise, good structure
- Predicted (PSNR: 50.00, SSIM: 0.9999): Indistinguishable from ground truth
- Assessment: Superior detail preservation, no artifacts

---
